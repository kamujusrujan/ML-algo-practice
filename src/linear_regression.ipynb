{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "261e823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc7fff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression model \n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Model(ABC) : \n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, X , Y) : pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def infer(self, X) : pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbbde6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(Model) : \n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        # self.dim = None\n",
    "        pass\n",
    "\n",
    "    def train(self,X , Y,epochs = 3,  learning_rate = 0.1 ):\n",
    "        N = X.shape[0]\n",
    "        dim = X.shape[1]\n",
    "        self.theta = np.random.rand(dim,1)  * 0.01\n",
    "        loop = tqdm(range(epochs))\n",
    "        loss_tracker = []\n",
    "        for e in loop : \n",
    "            for i in range(N) : \n",
    "                x_i = X[i].reshape(1, -1)\n",
    "                y_i = Y[i]\n",
    "                y_cap = self.infer(x_i)\n",
    "                error = (y_cap - y_i)      \n",
    "                loss_tracker.append(error)\n",
    "                update = (error * x_i.T)\n",
    "                self.theta = self.theta - (learning_rate * update ) \n",
    "                loop.set_postfix(loss = error)\n",
    "        return loss_tracker\n",
    "\n",
    "    def infer(self, X):\n",
    "        y_pred = X @ self.theta \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484accf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NormalEquationLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.theta = None\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        xt_x = X.T @ X\n",
    "        xt_x_inv = np.linalg.inv(xt_x)\n",
    "        # Formula: (X^T X)^-1 * X^T * Y\n",
    "        self.theta = xt_x_inv @ (X.T @ Y)\n",
    "\n",
    "    def infer(self, X):\n",
    "        return X @ self.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ef6f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (100, 2)\n",
      "Y shape: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "# X = np.random.rand(100, 10)\n",
    "# Y = np.ones(100,)\n",
    "# # theta = np.random.rand(10,1)\n",
    "# # pred =   theta @ X[0] \n",
    "# # theta - (pred * arr[0])  \n",
    "\n",
    "np.random.seed(42)\n",
    "N = 100 #samples\n",
    "dim = 2 #features\n",
    "X = 2 * np.random.rand(N, dim)\n",
    "true_theta = np.array([[2], [3]]) \n",
    "Y = X @ true_theta + np.random.randn(N, 1) * 0.1\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"Y shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0afef773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00c2f0f819241d4b6c7b769cec123a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "loss_ = model.train(X,Y, learning_rate= 0.01, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fea6ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.00669581],\n",
       "       [3.00539384]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7c3f05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete (Exact Solution Found)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.00765173],\n",
       "       [3.00704552]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NormalEquationLinearRegression()\n",
    "loss_ = model.train(X,Y)\n",
    "model.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89cd3803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a16b40238fe4989a72b5f2f17a560ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.93843892],\n",
       "       [0.52968363]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "N = 100\n",
    "X = 6 * np.random.rand(N, 1) - 3  # Range from -3 to 3\n",
    "# y = 0.5 * x^2 + x + noise\n",
    "Y = 0.5 * X**2 + X  + np.random.randn(N, 1)\n",
    "X_poly = np.hstack((X, X**2))\n",
    "model = LinearRegression() \n",
    "losses = model.train(X_poly, Y, epochs=100, learning_rate=0.001)\n",
    "model.theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489747f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(Model) : \n",
    "    \n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        pass\n",
    "    \n",
    "\n",
    "    def train(self,X , Y,epochs = 3,  learning_rate = 0.1 ):\n",
    "        N = X.shape[0]\n",
    "        dim = X.shape[1]\n",
    "        self.theta = np.random.rand(dim,1)  * 0.01\n",
    "        loop = tqdm(range(epochs))\n",
    "        loss_tracker = []\n",
    "        for e in loop : \n",
    "            for i in range(N) : \n",
    "                x_i = X[i].reshape(1, -1)\n",
    "                y_i = Y[i]\n",
    "                y_cap = self.infer(x_i)\n",
    "                error = (y_cap - y_i) # derivate of cross entropy\n",
    "                loss = - (y_i * np.log(y_cap) + (1 - y_i) * np.log(1 - y_cap))\n",
    "                loss_tracker.append(loss)\n",
    "                update = (error * x_i.T)\n",
    "                self.theta = self.theta - (learning_rate * update ) \n",
    "                loop.set_postfix(loss = loss)\n",
    "        return loss_tracker\n",
    "\n",
    "    def infer(self, X):\n",
    "        z =  X @ self.theta\n",
    "        \n",
    "        # limit the z for the exp function\n",
    "        z = np.clip(z, -20, 20)\n",
    "\n",
    "        y_pred = 1 / (1 + np.exp(-z))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5380bafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (200, 2)\n",
      "Y shape: (200, 1)\n",
      "Class balance: 100 ones vs 100 zeros\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "N = 200      # More samples helps visualization\n",
    "dim = 2      # Features\n",
    "\n",
    "X = np.random.randn(N, dim)\n",
    "\n",
    "true_theta = np.array([[12], [-3]]) \n",
    "z = X @ true_theta + np.random.randn(N, 1) * 0.5\n",
    "Y = (z > 0).astype(int)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"Y shape: {Y.shape}\")\n",
    "print(f\"Class balance: {np.sum(Y)} ones vs {N - np.sum(Y)} zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c770347e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2dd0ad53ba41859fdd3ce7048d2c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "loss_ = model.train(X,Y, learning_rate= 0.01, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f17fe8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.92910019],\n",
       "       [-1.13441145]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798d49d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
